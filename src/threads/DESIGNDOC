			+--------------------+
			|        CS 153      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

James Hollister <jholl013@ucr.edu> 
Roberto Pasillas <rpasi001@ucr.edu>  

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

None. 

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

None.
			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

static struct list sleep_list;
/*
The list structure was required to keep track of sleeping threads , without utilizing the cpu 
using the busy wait as previously implemented. 
*/

struct thread
{
...
int64_t awakeTime;                  /* Time to awake thread if sleeping */
struct list_elem sleepelem;         /* List element for sleeping list */
...
}
/*
Added awake_time which holds the amount of ticks that would need to have occured in order 
for the thread  to wake up if it was sleeping.
Added sleepelem that is needed for the sleep list above.
*/

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

First we save the current interrupt status

Then we set the current threads awake time to equal the current ticks
plus the ticks given as a parameter to the function call.

Then we disble interrups so that the we can have exclusive access to the list elements.

Then we do a sorted insert , where the sorting is based on the awake time , from high to low.

Then we block the thread.

Then re-set interrupts to the original level.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Since we have a sorted list based on the sorted insertions, we just need to check the top most elements of our
list to see if we need to awake the thread, rather then checking the entire list for the same check.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Through the use of system interrupts , we disable the context switcihing by disabling interrupts we accessing the 
shared resource sleeplist. Once we are done using the shared resource, we enable to the previous state.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

By obtaining our sorting element timer_ticks() and inserting into our sleep list when interrupts are diabled, 
we ensure that we don't have race condition about our shared resources.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose to implent using sorted insert because that would have a runtime of O(n) when inserting, 
but would allow for constant access time for the next element we need to access.

Another possible implementation was to insert unsorted , which would be a constant time insert, 
but O(n) access time. But we need to access elements at every tick, giving us a less efficient implementation.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
{
...
static struct list locks;
...
}

This list will be a list of locks that the thread currently holds. Used to access the threads
currently waiting on the lock to get a donated priority.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

SEE ATTACHED PNG

The attached image shows our structure implementation to realize the priority scheduler.

First, our thread structure will have a list of pointers to locks that it is holding.
Note: Only running threads can be lock holders, threads waiting on a lock are not considered lock holders.

Using the list of lock pointers, we can reference the waiting threads of the lock to determine the maximum priority 
that can be donated and see whats greater , the currently set priority or the donated priority. Although we will 
not change the priority of the running proccess, we will have a reference to this higher donated priority.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The locking structure has a list of waiting threads, and we extract the thread with the highest priority, 
including donated priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When a thread calls lock_acquire() it will attempt to take the lock, if it takes the lock it
will then lock structure will be added to its donations list. This way, each lock that a thread holds 
will be kept track of. Each lock in turn has a list of waiters that can be accessed in the get_priority
function to return the donated priority.

For nested donations the get_priority() function will recursively access the donated priority of each thread
in the wait list.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

To determine priority, we look at the return the max of the set priority vs the donated recursive get_priority(), 
after the lock is removed the get_priority() function will no longer have access to the locks waiting list, and thus
won't have access to the donated priority.

In terms of the locking thread, the release will set the pointer to the lock to null and lose reference to the
waiting list. So the thread will now run under its given priority.

In terms of the lock, waiting list will be searched to determine the higherst priority, including donated priorities 
from other held locks. The higherst priority thread will then be set as the lock holder.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Given that a function can call set priority on a thread, we could have the posibility of simultaniously setting
the priority variable of a thread. This variable could have a race condition. To avoid this race condition, we set 
the critical section of the function to run with interrupts off. This will give the function exclusive access to the 
priority, giving us an atomic region for the function.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

Our implementation had in mind that we wanted to prevent a thread from accessing cpu time , thus we needed a 
waiting structure to hold threads. Furthermore we needed an association between threads and locks to determine 
donated priority.

Our implementation was to save the waiting threads in the lock and add a pointer to the the lock to the holding 
thread. We concluded that this was an optimal solution as it removes threads from busy waiting cpu time and instead
focuses resources completing lock holding threads.

We did consider a thread_yield approach for threads that we on a waiting list. The pros were that most of the 
functionallity is already built in, the cons was that it is not optimal.

A possible draw back with our implementation is that if a locking thread never completes, neither will the waiting
threads, but thats inherent with locks.

			  ADVANCED SCHEDULER
			    (If Attempted)
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread 
{
...
int32_t nice;
int64_t recent_cpu;
...
}

Both nice and cpu are thread specific values that need to be stored for
the advanced scheduler.

static int load_avg;

A static integer to keep track of the total load average of the system.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59     A
 4      
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

The functions were pretty straight forward, but when and how often to call them
was the challenging part. The guidance led us to implement the functions in the 
timer_tick() function, which is called by the interrupt.so in essence it works with the interrupt.
Having the tick functions run with functions was key to proper value allocation with time
as crucial component.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

A potential draw back to our implementation is that having too many functions could cause the
interrupt function to interrupt itself. Given this constraint, we checked whether we needed to 
run the calculations or not by looking at the assertion variables. This way if the calculations are not needed
we don't waste CPU resources calculating said values.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

We would triple check the function implementation locations and conditionals that restrict
execution of the functions to minimize CPU utilization. We would also examine the conditionals to 
minimize the running of non required code.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We used macros to calculate our required functions to give use inline replacement of our code
during execution. Looking at it from an assembly instruction perspective, this would decrease the 
number of branches, minimizing CPU utilization. Furthermore, when implementing functions we simplified 
some arithmetic to give us fewer calculation steps.. Another benefit was to eliminate the use of magic numbers, 
where we have numbers only have meaning to the programmer and to simplify changes if there are/were any errors.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

We haven't finished the project yet so we don't know if it took too long. The complexity of this 
project is understanding the syntax , combined with new concept implementation.  So far this seems managable.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Learning theory is great, but theory implementation gives further insight into the concepts as one must
think about implementation issues that arise and the associated solutions.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

The guidance from the TA was very leading and helped our team focus on the implementation, instead of 
spending time finding the focus area. We still had to think of the solution so this help was great.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

Clear guidance as was given in project 1 will help with the subsequent projects. So far the guidance has been on point.

>> Any other comments?

